{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/buriy/russian-nlp-datasets/releases/download/r4/lenta.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700006, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Библиотека / Первая мировая</td>\n",
       "      <td>Бои у Сопоцкина и Друскеник закончились отступ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Библиотека / Первая мировая</td>\n",
       "      <td>Министерство народного просвещения, в виду про...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Библиотека / Первая мировая</td>\n",
       "      <td>Фотограф-корреспондент Daily Mirror рассказыва...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Библиотека / Первая мировая</td>\n",
       "      <td>Штабс-капитан П. Н. Нестеров на днях, увидев в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Библиотека / Первая мировая</td>\n",
       "      <td>Лица, приехавшие в Варшаву из Люблина, передаю...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        topics  \\\n",
       "0  Библиотека / Первая мировая   \n",
       "1  Библиотека / Первая мировая   \n",
       "2  Библиотека / Первая мировая   \n",
       "3  Библиотека / Первая мировая   \n",
       "4  Библиотека / Первая мировая   \n",
       "\n",
       "                                                text  \n",
       "0  Бои у Сопоцкина и Друскеник закончились отступ...  \n",
       "1  Министерство народного просвещения, в виду про...  \n",
       "2  Фотограф-корреспондент Daily Mirror рассказыва...  \n",
       "3  Штабс-капитан П. Н. Нестеров на днях, увидев в...  \n",
       "4  Лица, приехавшие в Варшаву из Люблина, передаю...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('lenta.tar.bz2',usecols = ['topics','text'])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topics    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topics.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Россия       116891\n",
       "Мир           95099\n",
       "Экономика     58247\n",
       "Спорт         42323\n",
       "Культура      34609\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topics.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Россия', 'Мир', 'Экономика'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take1st5topics = df.topics.value_counts().head(3).index\n",
    "take1st5topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270237, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.topics.isin(take1st5topics)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Мир', 'Россия', 'Экономика']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(df.topics)\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(df.topics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['Россия'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131885</th>\n",
       "      <td>На одной из веток петербургского метро было пр...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238186</th>\n",
       "      <td>Банду подростков из подмосковной Балашихи запо...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>Новым руководителем Московского художественног...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36169</th>\n",
       "      <td>В четверг вечером вертолет израильских ВВС нан...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59948</th>\n",
       "      <td>Татьяна Пичугина, супруга арестованного сотруд...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  target\n",
       "131885  На одной из веток петербургского метро было пр...       1\n",
       "238186  Банду подростков из подмосковной Балашихи запо...       1\n",
       "3680    Новым руководителем Московского художественног...       1\n",
       "36169   В четверг вечером вертолет израильских ВВС нан...       0\n",
       "59948   Татьяна Пичугина, супруга арестованного сотруд...       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = le.transform(df.topics)\n",
    "df.drop(['topics'],axis=1,inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((216189,), (54048,), (216189,), (54048,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.text,df.target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=df.target,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### построим простую модельку без препроцессинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.5 s, sys: 347 ms, total: 29.8 s\n",
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(min_df=0.1)\n",
    "cv_train = cv.fit_transform(X_train)\n",
    "cv_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'компании': 40,\n",
       " 'по': 65,\n",
       " 'на': 50,\n",
       " 'миллионов': 48,\n",
       " 'долларов': 26,\n",
       " 'что': 104,\n",
       " 'от': 63,\n",
       " '30': 3,\n",
       " 'до': 25,\n",
       " 'процентов': 74,\n",
       " 'году': 21,\n",
       " 'то': 95,\n",
       " 'же': 31,\n",
       " 'время': 14,\n",
       " 'года': 20,\n",
       " 'еще': 30,\n",
       " 'россии': 79,\n",
       " 'за': 32,\n",
       " 'он': 61,\n",
       " 'из': 34,\n",
       " 'частности': 102,\n",
       " 'для': 24,\n",
       " 'власти': 12,\n",
       " 'сообщает': 85,\n",
       " 'его': 27,\n",
       " 'рф': 81,\n",
       " 'они': 62,\n",
       " 'президента': 70,\n",
       " 'ранее': 75,\n",
       " 'уже': 100,\n",
       " 'заявил': 33,\n",
       " 'против': 73,\n",
       " 'об': 57,\n",
       " 'этом': 108,\n",
       " 'во': 13,\n",
       " 'связи': 82,\n",
       " 'не': 52,\n",
       " 'было': 11,\n",
       " 'решение': 77,\n",
       " 'может': 49,\n",
       " 'передает': 64,\n",
       " 'которые': 42,\n",
       " 'между': 47,\n",
       " 'тем': 94,\n",
       " 'напомним': 51,\n",
       " 'как': 38,\n",
       " 'будет': 6,\n",
       " 'под': 66,\n",
       " 'были': 10,\n",
       " 'глава': 19,\n",
       " 'был': 8,\n",
       " 'словам': 83,\n",
       " 'того': 96,\n",
       " 'только': 97,\n",
       " 'после': 68,\n",
       " 'этого': 107,\n",
       " 'сообщил': 87,\n",
       " 'страны': 89,\n",
       " 'более': 5,\n",
       " 'результате': 76,\n",
       " 'том': 98,\n",
       " 'будут': 7,\n",
       " 'ходе': 101,\n",
       " 'которого': 41,\n",
       " 'агентство': 4,\n",
       " 'пока': 67,\n",
       " 'сша': 91,\n",
       " 'ее': 28,\n",
       " 'однако': 59,\n",
       " 'при': 72,\n",
       " 'также': 93,\n",
       " 'лет': 46,\n",
       " 'интерфакс': 36,\n",
       " 'со': 84,\n",
       " 'ссылкой': 88,\n",
       " 'пресс': 71,\n",
       " 'суд': 90,\n",
       " 'сообщается': 86,\n",
       " 'когда': 39,\n",
       " 'чтобы': 105,\n",
       " 'рублей': 80,\n",
       " 'данным': 22,\n",
       " 'который': 43,\n",
       " 'является': 109,\n",
       " 'где': 18,\n",
       " 'несколько': 53,\n",
       " 'один': 58,\n",
       " 'около': 60,\n",
       " 'все': 15,\n",
       " '10': 0,\n",
       " 'газета': 17,\n",
       " 'это': 106,\n",
       " 'но': 55,\n",
       " 'их': 37,\n",
       " 'кроме': 45,\n",
       " 'тысяч': 99,\n",
       " '20': 2,\n",
       " 'президент': 69,\n",
       " 'если': 29,\n",
       " 'была': 9,\n",
       " 'которых': 44,\n",
       " 'так': 92,\n",
       " 'или': 35,\n",
       " 'два': 23,\n",
       " 'риа': 78,\n",
       " 'новости': 56,\n",
       " 'человек': 103,\n",
       " 'всего': 16,\n",
       " '15': 1,\n",
       " 'них': 54}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7625999111900533\n",
      "\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77     19020\n",
      "           1       0.77      0.78      0.77     23378\n",
      "           2       0.79      0.68      0.73     11650\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     54048\n",
      "   macro avg       0.77      0.75      0.76     54048\n",
      "weighted avg       0.76      0.76      0.76     54048\n",
      "\n",
      "\n",
      "confusion_matrix:\n",
      "[[15175  3146   699]\n",
      " [ 3913 18120  1345]\n",
      " [ 1448  2280  7922]]\n",
      "CPU times: user 24.9 s, sys: 3.83 ms, total: 24.9 s\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression()\n",
    "lr.fit(cv_train,y_train)\n",
    "\n",
    "pred_lr = lr.predict(cv_test)\n",
    "print('accuracy =',accuracy_score(y_test,pred_lr))\n",
    "print('\\nclassification_report:')\n",
    "print(classification_report(y_test,pred_lr))\n",
    "print('\\nconfusion_matrix:')\n",
    "print(confusion_matrix(y_test,pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe = Pipeline([('vec', CountVectorizer(min_df=0.1)),\n",
    "#                 ('clf', LogisticRegression())\n",
    "#                 ]\n",
    "#               )\n",
    "#                  \n",
    "#pipe.fit(X_train,y_train)\n",
    "#\n",
    "#pred_lr = pipe.predict(X_test)\n",
    "#print('accuracy =',accuracy_score(y_test,pred_lr))\n",
    "#print('\\nclassification_report:')\n",
    "#print(classification_report(y_test,pred_lr))\n",
    "#print('\\nconfusion_matrix:')\n",
    "#print(confusion_matrix(y_test,pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### построим простую модельку с препроцессингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "\n",
    "from razdel import tokenize # https://github.com/natasha/razdel\n",
    "#!pip install razdel\n",
    "\n",
    "import pymorphy2  # pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "len(stopword_ru)\n",
    "\n",
    "with open('../stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    for w in f.readlines():\n",
    "        stopword_ru.append(w)\n",
    "        \n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "   \n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В минувший четверг президент РФ Борис Ельцин п...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ИТАР-ТАСС со ссылкой на пресс-службу Миноборон...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  В минувший четверг президент РФ Борис Ельцин п...       1\n",
       "1  ИТАР-ТАСС со ссылкой на пресс-службу Миноборон...       1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 116 ms, total: 1min 11s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['clean_text'] = df.text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В минувший четверг президент РФ Борис Ельцин п...</td>\n",
       "      <td>1</td>\n",
       "      <td>в минувший четверг президент рф борис ельцин п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ИТАР-ТАСС со ссылкой на пресс-службу Миноборон...</td>\n",
       "      <td>1</td>\n",
       "      <td>итартасс со ссылкой на прессслужбу минобороны ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  В минувший четверг президент РФ Борис Ельцин п...       1   \n",
       "1  ИТАР-ТАСС со ссылкой на пресс-службу Миноборон...       1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  в минувший четверг президент рф борис ельцин п...  \n",
       "1  итартасс со ссылкой на прессслужбу минобороны ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка на стоп-слова\n",
    "        [4] проверка токена с одного символа\n",
    "        [5] проверка есть ли данное слово в кэше\n",
    "        [6] лемматизация слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    \n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if not w in stopword_ru: # [3]\n",
    "            if len(w)>1: # [4]\n",
    "                if w in cache: # [5]\n",
    "                    words_lem.append(cache[w])\n",
    "                else: # [6]\n",
    "                    temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                    words_lem.append(temp_cach)\n",
    "    return words_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['lemma_clean_text'] = df.text.apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['join_lemma_clean_text'] = df.lemma_clean_text.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.join_lemma_clean_text,df.target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=df.target,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(min_df=0.1)\n",
    "cv_train = cv.fit_transform(X_train)\n",
    "cv_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr = LogisticRegression()\n",
    "lr.fit(cv_train,y_train)\n",
    "\n",
    "pred_lr = lr.predict(cv_test)\n",
    "print('accuracy =',accuracy_score(y_test,pred_lr))\n",
    "print('\\nclassification_report:')\n",
    "print(classification_report(y_test,pred_lr))\n",
    "print('\\nconfusion_matrix:')\n",
    "print(confusion_matrix(y_test,pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
